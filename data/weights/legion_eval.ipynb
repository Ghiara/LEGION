{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"Set the seed for python, numpy, and torch.\n",
    "\n",
    "    Args:\n",
    "        seed (int): seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)  # type: ignore\n",
    "    # Module has no attribute \"manual_seed_all\"  [attr-defined]\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "LOAD_PATH = './ckpt/'\n",
    "set_seed(2)\n",
    "file_names = ['task_encoder_0.95.pt', 'vae_0.95.pt', 'actor_0.95.pt']\n",
    "\n",
    "\n",
    "# LOAD_PATH = './02/'\n",
    "# set_seed(3)\n",
    "# file_names = ['task_encoder_1.0.pt', 'vae_1.0.pt', 'actor_1.0.pt']\n",
    "\n",
    "# LOAD_PATH = './03/'\n",
    "# set_seed(3)\n",
    "# file_names = ['task_encoder_0.99.pt', 'vae_0.99.pt', 'actor_0.99.pt']\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(22, 300),\n",
    "            nn.LayerNorm(300),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(300, 300),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(300, 300),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(300, 300),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(300, 8),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "class VAE_Inference(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.trunk = nn.Sequential(\n",
    "            nn.Linear(in_features=780, out_features=400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=400, out_features=400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=400, out_features=400),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.mu_latent = nn.Linear(in_features=400, out_features=10)\n",
    "        self.log_var_latent = nn.Linear(in_features=400, out_features=10)\n",
    "        self.decoder_context = nn.Sequential(\n",
    "            nn.Linear(in_features=10, out_features=400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=400, out_features=400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=400, out_features=400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=400, out_features=768),\n",
    "        )\n",
    "        self.decoder_state = nn.Sequential(\n",
    "            nn.Linear(in_features=26, out_features=400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=400, out_features=400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=400, out_features=400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=400, out_features=12),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        mu = self.mu_latent(self.trunk(input))\n",
    "        log_var = self.log_var_latent(self.trunk(input))\n",
    "        z = self.sample(mu, log_var)\n",
    "        return z, mu, log_var\n",
    "        \n",
    "    \n",
    "    def sample(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) log variance of the latent Gaussian [B x D]\n",
    "        :return: z (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "class Task_Encoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.pretrained_embedding = nn.Embedding(10, 768)\n",
    "    \n",
    "    def forward(self, task_idx):\n",
    "        return self.pretrained_embedding(task_idx)\n",
    "\n",
    "class LEGION(nn.Module):\n",
    "    '''\n",
    "    Legion for final evaluation\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.pretrain_language_module = Task_Encoder()\n",
    "        self.pretrain_language_module.load_state_dict(torch.load(LOAD_PATH+file_names[0]))\n",
    "\n",
    "        self.task_inference_module = VAE_Inference()\n",
    "        self.task_inference_module.load_state_dict(torch.load(LOAD_PATH+file_names[1]))\n",
    "\n",
    "        self.policy_module = Actor()\n",
    "        self.policy_module.load_state_dict(torch.load(LOAD_PATH+file_names[2]))\n",
    "\n",
    "        self.task_inference_module = self.task_inference_module.requires_grad_(False)\n",
    "        self.pretrain_language_module = self.pretrain_language_module.requires_grad_(False)\n",
    "        self.policy_module = self.policy_module.requires_grad_(False)\n",
    "    \n",
    "    def forward(self, mtobs:dict, return_z:bool=False):\n",
    "        env_obs = mtobs['env_obs']\n",
    "        task_idx = mtobs['task_obs']\n",
    "        language_encoding = self.pretrain_language_module(task_idx)\n",
    "        # language_encoding = self.pretrain_language_module(torch.tensor([task_idx]))\n",
    "        # env_obs = torch.tensor(observation)\n",
    "        vae_input = torch.cat([env_obs, language_encoding], dim=-1)\n",
    "\n",
    "        latent_obs, _, _ = self.task_inference_module(vae_input.float())\n",
    "\n",
    "        actor_obs = torch.cat([env_obs, latent_obs], dim=-1)\n",
    "        mu_and_log_std = self.policy_module(actor_obs.float())\n",
    "        action, _ = mu_and_log_std.chunk(2, dim=-1)\n",
    "        action = torch.tanh(action)\n",
    "        if return_z:\n",
    "            return action.detach().cpu().numpy(), latent_obs.detach().cpu().numpy()\n",
    "        else:\n",
    "            return action.detach().cpu().numpy()\n",
    "\n",
    "legion = LEGION()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuan/miniconda3/envs/meta/lib/python3.7/site-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reach-v2', 'push-v2', 'pick-place-v2', 'door-open-v2', 'faucet-open-v2', 'drawer-close-v2', 'button-press-topdown-v2', 'peg-unplug-side-v2', 'window-open-v2', 'window-close-v2']\n"
     ]
    }
   ],
   "source": [
    "import metaworld\n",
    "from mtenv.envs.metaworld.env import get_list_of_envs\n",
    "benchmark_name = 'MT10_KUKA'\n",
    "benchmark=metaworld.MT10_KUKA()\n",
    "env_id_to_task_map=None\n",
    "make_kwargs = {\n",
    "    \"benchmark\": benchmark,\n",
    "    \"benchmark_name\": benchmark_name, # MT10, MT50\n",
    "    \"env_id_to_task_map\": env_id_to_task_map,\n",
    "    \"num_copies_per_env\": 1,\n",
    "    \"should_perform_reward_normalization\": True,\n",
    "}\n",
    "list_envs, env_id_to_task_map = get_list_of_envs(\n",
    "    **make_kwargs\n",
    ")\n",
    "max_episode_steps=150\n",
    "agent = legion.train(False)\n",
    "task_obs = torch.arange(len(list_envs))\n",
    "env_names =  list(env_id_to_task_map.keys())\n",
    "select_env = [\n",
    "    'reach-v2', \n",
    "    'push-v2', \n",
    "    'pick-place-v2', \n",
    "    'door-open-v2', \n",
    "    'faucet-open-v2', \n",
    "    'drawer-close-v2', \n",
    "    'button-press-topdown-v2', \n",
    "    'peg-unplug-side-v2', \n",
    "    'window-open-v2', \n",
    "    'window-close-v2'\n",
    "    ]\n",
    "\n",
    "\n",
    "print(env_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env reach-v2, success 1.0\n",
      "env push-v2, success 1.0\n",
      "env pick-place-v2, success 1.0\n",
      "env door-open-v2, success 1.0\n",
      "env faucet-open-v2, success 1.0\n",
      "env drawer-close-v2, success 1.0\n",
      "env button-press-topdown-v2, success 1.0\n",
      "env peg-unplug-side-v2, success 1.0\n",
      "env window-open-v2, success 1.0\n",
      "env window-close-v2, success 1.0\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "show_latent_z = False\n",
    "record = False\n",
    "render = False\n",
    "width=1024 \n",
    "height=1024\n",
    "\n",
    "\n",
    "# for env_idx in range(len(env_names)):\n",
    "# for env in select_env:\n",
    "for env in [\n",
    "    'reach-v2', \n",
    "    'push-v2',\n",
    "    'pick-place-v2',\n",
    "    'door-open-v2', \n",
    "    'faucet-open-v2', \n",
    "    'drawer-close-v2', \n",
    "    'button-press-topdown-v2', \n",
    "    'peg-unplug-side-v2',\n",
    "    'window-open-v2', \n",
    "    'window-close-v2'\n",
    "    ]:\n",
    "    env_idx = env_names.index(env)\n",
    "    # reset\n",
    "    latent_traj=[]\n",
    "    traj_obs=[]\n",
    "    traj_actions = []\n",
    "    episode_step = 0           \n",
    "    env_obs = []\n",
    "    success = 0.0\n",
    "\n",
    "\n",
    "    obs = list_envs[env_idx].reset()\n",
    "    env_obs.append(obs)\n",
    "    multitask_obs = {\"env_obs\": torch.tensor(env_obs), \"task_obs\": torch.tensor([env_idx])}\n",
    "    \n",
    "    if record:\n",
    "        writer = imageio.get_writer(f'{env}.mp4', fps=30)\n",
    "        writer.append_data(list_envs[env_idx].render('rgb_array', width=width, height=height))\n",
    "        # frames.append(list_envs[env_idx].render('rgb_array', width=width, height=height))\n",
    "    elif render:\n",
    "        list_envs[env_idx].render()\n",
    "    \n",
    "        \n",
    "    for episode_step in range(max_episode_steps):\n",
    "        # agent select action\n",
    "        with torch.no_grad():\n",
    "            if show_latent_z:\n",
    "                action, z = agent(multitask_obs, return_z=True)\n",
    "                latent_traj.append(z)\n",
    "            else:\n",
    "                action = agent(multitask_obs)\n",
    "        # interactive with envs get new obs\n",
    "        env_obs = []\n",
    "        obs, reward, done, info = list_envs[env_idx].step(action[0])\n",
    "        if record:\n",
    "            # frames.append(list_envs[env_idx].render('rgb_array', width=width, height=height))\n",
    "            writer.append_data(list_envs[env_idx].render('rgb_array', width=width, height=height))\n",
    "        elif render:\n",
    "            list_envs[env_idx].render()\n",
    "\n",
    "        if (episode_step+1) % max_episode_steps == 0:\n",
    "            obs = list_envs[env_idx].reset()\n",
    "\n",
    "        env_obs.append(obs)\n",
    "        success += info['success']\n",
    "\n",
    "\n",
    "        multitask_obs = {\"env_obs\": torch.tensor(env_obs), \"task_obs\": torch.tensor([env_idx])}\n",
    "        episode_step += 1\n",
    "\n",
    "    success = float(success > 0)\n",
    "    print(f'env {env_names[env_idx]}, success {success}')\n",
    "    if show_latent_z:\n",
    "        np.save(f'latent_{env}.npy',latent_traj)\n",
    "    if not record:\n",
    "        list_envs[env_idx].close()\n",
    "    else:\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
